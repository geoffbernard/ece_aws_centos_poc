

#Do the following iteration for each host - two separate routines one for setting up drives below
# depending on if there is one nvme or more than 1
# assumtion is build to be done on i3?s for performance

# the below instructions are based on 
# 1. centos/rhel instructions at:
#    https://www.elastic.co/guide/en/cloud-enterprise/current/ece-configure-hosts-rhel-centos.html
#
# 2. LVM basics 
#
# 3. set up routine for aws image, see video here:
#    https://drive.google.com/file/d/13MoC0e7hCU-f0xRZekFF23XLdlnSsYX_/view?usp=sharing
#    for sample server topologies check out the playbooks:
#	 https://www.elastic.co/guide/en/cloud-enterprise/current/ece-playbook.html
#
# Note: for server incoming/outgoing security group rules, configure this:
#          https://www.elastic.co/guide/en/cloud-enterprise/current/ece-prereqs-networking.html
#          in video above, security group is already built
#          if feeling dangerous and short of time, 
#          one could always set up ?ALL? settings and then do this right as per network instrucions post-install
#          eliminating POF?s

# need to build out a Centos image with ECE on it
# there is one already built for you but needs more work done to it, as per below linux routines 
#
#search for AMI on public with string ?elastic-cloud-enterprise? with  Centos label
#pick the Centos image with the latest date (we will update image below with tuned settings)
#next optimize hardware and network to specific needs
#for ease of access in a quick start, enable public access to instance and i3 
#if planning to use vpc across physicals AZ?s, keep in mind the AWS ingress/egress costs
#especially if planning to test out Rally
#otherwise a simple 

#below is a good place for a terraform configuration or other script! :)
# (minimizing cloud vendor dependency)

#get Centos updates
sudo yum update
sudo reboot

#some maintenance settings
sudo /sbin/grubby --update-kernel=ALL --args='cgroup_enable=memory cgroup.memory=nokmem swapaccount=1'
echo "overlay" | sudo tee -a /etc/modules-load.d/overlay.conf
sudo grub2-set-default 0
sudo grub2-mkconfig -o /etc/grub2.cfg

#run below - all one line - sets up Docker repo
sudo tee /etc/yum.repos.d/docker.repo <<-'EOF'
[dockerrepo]
name=Docker Repository
baseurl=https://download.docker.com/linux/centos/7/x86_64/stable
enabled=1
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg
EOF

#more docker setup
sudo yum makecache fast
sudo yum install docker-ce-18.09.2*
sudo docker version

#get partition name/s - if more than one, raid 0
echo $(sudo lsblk | awk '/^nvme/ {printf "/dev/%s ", $1}')

# if going with i3, the below will workd - first block below if for one disk
# second block is for multiple disks of instance storage (nvme)

#two choices below: (1) one nvme or (2) multiple nvme

#???????????start of one drive approach

#set up xfs and mount - also enable user
sudo mkfs.xfs /dev/nvme0n1
sudo mount -o discard /dev/nvme0n1 /mnt/data
sudo chown $USER:$USER /mnt/data

#update fstab
sudo vi /etc/fstab

# Comment out mnt/data line present and put this line instead in fstab 
/dev/nvme0n1      /mnt/data       xfs     defaults,nofail,x-systemd.automount,prjquota,pquota  0 2
#/dev/lxc/data /mnt/data  xfs   defaults,pquota,prjquota,x-systemd.automount  0 0

#???????????end of one drive approach

#???????????start of multiple drive approach - LVM - below

# this assumes four drives
# take away and add nvme drives below as appropriate
# the -i setting in lvcreate needs to match number of drives (stripes)
sudo pvcreate /dev/nvme0n1
sudo pvcreate /dev/nvme1n1
sudo pvcreate /dev/nvme2n1
sudo pvcreate /dev/nvme3n1
sudo vgcreate eceVG /dev/nvme0n1 /dev/nvme1n1 /dev/nvme2n1 /dev/nvme3n1
sudo lvcreate -i 4 -I 8 -l 100%FREE eceVG -n eceLV
sudo mkfs.xfs /dev/eceVG/eceLV
sudo mount /dev/eceVG/eceLV /mnt/data
sudo chown $USER:$USER /mnt/data
sudo install -o $USER -g $USER -d -m 700 /mnt/data

#update fstab
sudo vi /etc/fstab

# Comment out mnt/data line present and put following
/dev/eceVG/eceLV     /mnt/data       xfs     defaults,nofail,x-systemd.automount,prjquota,pquota  0 2
#/dev/lxc/data /mnt/data  xfs   defaults,pquota,prjquota,x-systemd.automount  0 0

#????????????end of multiple drive approach

#now for docker and more system settings
sudo systemctl daemon-reload
sudo systemctl restart local-fs.target
sudo systemctl stop docker
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
cat /proc/sys/fs/may_detach_mounts

sudo vi /etc/sysctl.conf

#add these lines to sysctl file - in aws i3, both settings need to be added

#one for helping docker cleanly remove containers 
fs.may_detach_mounts = 1

#other for enabling port forwarding - helps docker work
net.ipv4.ip_forward = 1


# skip this step from instructions doesn?t work on aws image user shell
#sudo service network restart - reboot instead 
sudo reboot

# <??run this make sure you get 1 having rebooted
cat /proc/sys/net/ipv4/ip_forward  

# update limit settings as per instructions #5 at 
#     https://www.elastic.co/guide/en/cloud-enterprise/current/ece-configure-hosts-rhel-centos.html
#     install will work without this, but probably smart to have for prod env
#     /etc/security/limits.conf

# for ECE AMI, $USER is elastic
#     echo $USER

# at this point, free to run a quick lsblk -f and df -Th 
#.    and admire all your LVM work if working with multiple drive!
#     lsblk -f
#     df -Th

# set up docker directory for mount on write drive 
#     for some reason install command on its own is a bit stubborn at AWS image
#     so just set up directory first and then run command for safe measure
cd /mnt/data
sudo mkdir docker
sudo install -o $USER -g $USER -d -m 700 /mnt/data/docker

#firewalld has to be off for ece to work right
sudo systemctl disable firewalld
  
#update docker configuration file
sudo vi /etc/systemd/system/docker.service.d/docker.conf

# replace entire file with:
[Unit]
Description=Docker Service
After=multi-user.target

[Service]
ExecStart=
ExecStart=/usr/bin/dockerd --data-root /mnt/data/docker --storage-driver=overlay --bip=172.17.42.1/16

#end of replacement ^^^^

#more docker settings below
sudo systemctl daemon-reload
sudo systemctl restart docker
sudo systemctl enable docker
sudo usermod -aG docker $USER

#run below block on command line
cat << SETTINGS | sudo tee /etc/sysctl.d/70-cloudenterprise.conf
net.ipv4.tcp_max_syn_backlog=65536
net.core.somaxconn=32768
net.core.netdev_max_backlog=32768
SETTINGS
#end of block ^^^^

#end of docker setup here
echo "exclude=docker-ce" | sudo tee -a /etc/yum.conf
sudo reboot

#check stuff - nice to check, not required steps
sudo docker info | grep Root
lsblk -f
cat /proc/sys/net/ipv4/ip_forward

#this line only works now - didnt work in place of above directory creation 
#prior to reboot, but has to run for ECE install to work
sudo install -o $USER -g $USER -d -m 700 /mnt/data


# prereqs all set!

# ?????????beginning of ECE installation

# now for installation notes for actual ECE install
#    first server is a simple one liner with all prereq?s all working and set up right
#    there are lots of install configuration parameters, but for a simple install, go with below

#do this for first host (server 1)
#     replace:
#           zone-1 with favorite zone name - physical az does not matter here

bash <(curl -fsSL https://download.elastic.co/cloud/elastic-cloud-enterprise.sh) install --availability-zone MY_ZONE-1 --memory-settings '{"runner":{"xms":"1G","xmx":"1G"},"allocator":{"xms":"4G","xmx":"4G"},"proxy":{"xms":"8G","xmx":"8G"},"zookeeper":{"xms":"4G","xmx":"4G"},"director":{"xms":"1G","xmx":"1G"},"constructor":{"xms":"4G","xmx":"4G"},"admin-console":{"xms":"4G","xmx":"4G"}}'

# when install done, write down all settings output on shell 
#   admin password, URL?s, and tokens are most interesting - try not to lose these!

#do this for servers 2 and 3 and every other host
#   substitute:
#         above token for ?MY_TOKEN?
#         ?MY-ZONE-2? with desired zone name for each host - ok to put more than one host in a zone
#         ?coordinator-host? with local IP address of server 1 (e.g. 10.0.x.x) 

bash <(curl -fsSL https://download.elastic.co/cloud/elastic-cloud-enterprise.sh) install --coordinator-host HOST_IP --roles-token 'MY_TOKEN' --roles "director,coordinator,proxy,allocator" --availability-zone MY_ZONE-2 --memory-settings '{"runner":{"xms":"1G","xmx":"1G"},"allocator":{"xms":"4G","xmx":"4G"},"proxy":{"xms":"8G","xmx":"8G"},"zookeeper":{"xms":"4G","xmx":"4G"},"director":{"xms":"1G","xmx":"1G"},"constructor":{"xms":"4G","xmx":"4G"},"admin-console":{"xms":"4G","xmx":"4G"}}'

#?????????end of ECE installation

# below are some added information, past the first server
#    these are provided simply for examples to compare to when following above instructions

#get a new token to use for servers 2 and 3 - write it down - new token is not required, basic will work
curl -k -H 'Content-Type: application/json' -u admin:password https://coordinator host:12443/api/v1/platform/configuration/security/enrollment-tokens -d '{ "persistent": false, "roles": ["director", "coordinator", "proxy", "allocator"] }'

#some real samples - servers 2,3,4
bash <(curl -fsSL https://download.elastic.co/cloud/elastic-cloud-enterprise.sh) install --coordinator-host 10.0.0.21 --roles-token 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIwMGQ4ZGUxNS1lZjBmLTQ2ZTMtYjZhNi1kYzg2ODhmNmU4NjIiLCJyb2xlcyI6WyJkaXJlY3RvciIsImNvb3JkaW5hdG9yIiwicHJveHkiLCJhbGxvY2F0b3IiXSwiaXNzIjoiY3VycmVudCIsImV4cCI6MTU2NzkwMDYwOH0.Ya5nDoCmgtnxNwM7DQfzul2jKFwyHN0zLyK4yw6aOHg' --roles "director,coordinator,proxy,allocator" --availability-zone MY_ZONE-2 --memory-settings '{"runner":{"xms":"1G","xmx":"1G"},"allocator":{"xms":"4G","xmx":"4G"},"proxy":{"xms":"8G","xmx":"8G"},"zookeeper":{"xms":"4G","xmx":"4G"},"director":{"xms":"1G","xmx":"1G"},"constructor":{"xms":"4G","xmx":"4G"},"admin-console":{"xms":"4G","xmx":"4G"}}'

bash <(curl -fsSL https://download.elastic.co/cloud/elastic-cloud-enterprise.sh) install --coordinator-host 10.0.0.21 --roles-token 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIwMGQ4ZGUxNS1lZjBmLTQ2ZTMtYjZhNi1kYzg2ODhmNmU4NjIiLCJyb2xlcyI6WyJkaXJlY3RvciIsImNvb3JkaW5hdG9yIiwicHJveHkiLCJhbGxvY2F0b3IiXSwiaXNzIjoiY3VycmVudCIsImV4cCI6MTU2NzkwMDYwOH0.Ya5nDoCmgtnxNwM7DQfzul2jKFwyHN0zLyK4yw6aOHg' --roles "director,coordinator,proxy,allocator" --availability-zone MY_ZONE-3 --memory-settings '{"runner":{"xms":"1G","xmx":"1G"},"allocator":{"xms":"4G","xmx":"4G"},"proxy":{"xms":"8G","xmx":"8G"},"zookeeper":{"xms":"4G","xmx":"4G"},"director":{"xms":"1G","xmx":"1G"},"constructor":{"xms":"4G","xmx":"4G"},"admin-console":{"xms":"4G","xmx":"4G"}}'

bash <(curl -fsSL https://download.elastic.co/cloud/elastic-cloud-enterprise.sh) install --coordinator-host 10.0.0.21 --roles-token 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIwMGQ4ZGUxNS1lZjBmLTQ2ZTMtYjZhNi1kYzg2ODhmNmU4NjIiLCJyb2xlcyI6WyJkaXJlY3RvciIsImNvb3JkaW5hdG9yIiwicHJveHkiLCJhbGxvY2F0b3IiXSwiaXNzIjoiY3VycmVudCIsImV4cCI6MTU2NzkwMDYwOH0.Ya5nDoCmgtnxNwM7DQfzul2jKFwyHN0zLyK4yw6aOHg' --roles "director,coordinator,proxy,allocator" --availability-zone MY_ZONE-3 --memory-settings '{"runner":{"xms":"1G","xmx":"1G"},"allocator":{"xms":"4G","xmx":"4G"},"proxy":{"xms":"8G","xmx":"8G"},"zookeeper":{"xms":"4G","xmx":"4G"},"director":{"xms":"1G","xmx":"1G"},"constructor":{"xms":"4G","xmx":"4G"},"admin-console":{"xms":"4G","xmx":"4G"}}'

